{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Kayak](https://seekvectorlogo.com/wp-content/uploads/2018/01/kayak-vector-logo.png)\n",
    "\n",
    "# Plan your trip with Kayak\n",
    "\n",
    "## Company's description üìá\n",
    "\n",
    "<a href=\"https://www.kayak.com\" target=\"_blank\">Kayak</a> is a travel search engine that helps user plan their next trip at the best price.\n",
    "\n",
    "The company was founded in 2004 by Steve Hafner & Paul M. English. After a few rounds of fundraising, Kayak was acquired by <a href=\"https://www.bookingholdings.com/\" target=\"_blank\">Booking Holdings</a> which now holds:\n",
    "\n",
    "* <a href=\"https://booking.com/\" target=\"_blank\">Booking.com</a>\n",
    "* <a href=\"https://kayak.com/\" target=\"_blank\">Kayak</a>\n",
    "* <a href=\"https://www.priceline.com/\" target=\"_blank\">Priceline</a>\n",
    "* <a href=\"https://www.agoda.com/\" target=\"_blank\">Agoda</a>\n",
    "* <a href=\"https://Rentalcars.com/\" target=\"_blank\">RentalCars</a>\n",
    "* <a href=\"https://www.opentable.com/\" target=\"_blank\">OpenTable</a>\n",
    "\n",
    "With over \\$300 million revenue a year, Kayak operates in almost all countries and all languages to help their users book travels accros the globe.\n",
    "\n",
    "## Project üöß\n",
    "\n",
    "The marketing team needs help on a new project. After doing some user research, the team discovered that **70% of their users who are planning a trip would like to have more information about the destination they are going to**.\n",
    "\n",
    "In addition, user research shows that **people tend to be defiant about the information they are reading if they don't know the brand** which produced the content.\n",
    "\n",
    "Therefore, Kayak Marketing Team would like to create an application that will recommend where people should plan their next holidays. The application should be based on real data about:\n",
    "\n",
    "* Weather\n",
    "* Hotels in the area\n",
    "\n",
    "The application should then be able to recommend the best destinations and hotels based on the above variables at any given time.\n",
    "\n",
    "## Goals üéØ\n",
    "\n",
    "As the project has just started, your team doesn't have any data that can be used to create this application. Therefore, your job will be to:\n",
    "\n",
    "* Scrape data from destinations\n",
    "* Get weather data from each destination\n",
    "* Get hotels' info about each destination\n",
    "* Store all the information above in a data lake\n",
    "* Extract, transform and load cleaned data from your datalake to a data warehouse\n",
    "\n",
    "## Scope of this project üñºÔ∏è\n",
    "\n",
    "Marketing team wants to focus first on the best cities to travel to in France. According <a href=\"https://one-week-in.com/35-cities-to-visit-in-france/\" target=\"_blank\">One Week In.com</a> here are the top-35 cities to visit in France:\n",
    "\n",
    "```python\n",
    "[\"Mont Saint Michel\", \"St Malo\", \"Bayeux\", \"Le Havre\", \"Rouen\", \"Paris\",\n",
    "\"Amiens\", \"Lille\", \"Strasbourg\", \"Chateau du Haut Koenigsbourg\", \"Colmar\",\n",
    "\"Eguisheim\", \"Besancon\", \"Dijon\", \"Annecy\", \"Grenoble\", \"Lyon\", \"Gorges du Verdon\",\n",
    "\"Bormes les Mimosas\", \"Cassis\", \"Marseille\", \"Aix en Provence\", \"Avignon\", \"Uzes\",\n",
    "\"Nimes\", \"Aigues Mortes\", \"Saintes Maries de la mer\", \"Collioure\", \"Carcassonne\",\n",
    "\"Ariege\", \"Toulouse\", \"Montauban\", \"Biarritz\", \"Bayonne\", \"La Rochelle\"]\n",
    "```\n",
    "\n",
    "Your team should focus **only on the above cities for your project**.\n",
    "\n",
    "## Deliverable üì¨\n",
    "\n",
    "To complete this project, your team should deliver:\n",
    "\n",
    "* A `.csv` file in an S3 bucket containing enriched information about weather and hotels for each french city\n",
    "* A SQL Database where we should be able to get the same cleaned data from S3\n",
    "* Two maps where you should have a Top-5 destinations and a Top-20 hotels in the area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get weather data with API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = [\n",
    "    \"Mont Saint Michel\", \"St Malo\", \"Bayeux\", \"Le Havre\", \"Rouen\", \"Paris\",\n",
    "    \"Amiens\", \"Lille\", \"Strasbourg\", \"Chateau du Haut Koenigsbourg\", \"Colmar\",\n",
    "    \"Eguisheim\", \"Besancon\", \"Dijon\", \"Annecy\", \"Grenoble\", \"Lyon\", \"Gorges du Verdon\",\n",
    "    \"Bormes les Mimosas\", \"Cassis\", \"Marseille\", \"Aix en Provence\", \"Avignon\", \"Uzes\",\n",
    "    \"Nimes\", \"Aigues Mortes\", \"Saintes Maries de la mer\", \"Collioure\", \"Carcassonne\",\n",
    "    \"Ariege\", \"Toulouse\", \"Montauban\", \"Biarritz\", \"Bayonne\", \"La Rochelle\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data recovery\n",
    "list_ = []\n",
    "count_city = 0\n",
    "\n",
    "for city in cities:\n",
    "    count_city += 1\n",
    "    url = \"https://nominatim.openstreetmap.org/search?q=\" + city + \"&format=json&countrycodes=fr&limit=0\"\n",
    "    response = requests.get(url)\n",
    "    lat = response.json()[0][\"lat\"]\n",
    "    lon = response.json()[0][\"lon\"]\n",
    "    \n",
    "    dict_ = {\n",
    "        \"id\": count_city,\n",
    "        \"city\": city,\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon\n",
    "    }\n",
    "    \n",
    "    list_.append(dict_)\n",
    "\n",
    "# dataframe creation\n",
    "dataset_nominatim = pd.DataFrame(list_)\n",
    "\n",
    "# current temperature retrieval\n",
    "list_ = []\n",
    "\n",
    "for i in range(len(dataset_nominatim)):\n",
    "    url = \"https://api.openweathermap.org/data/2.5/onecall?lat=\" + dataset_nominatim.latitude[i] + \"&lon=\" + dataset_nominatim.longitude[i] + \"&exclude=minutely,hourly,alerts&appid=50c2f1c97c97d43a85cdbab142865185&units=metric\"\n",
    "    response = requests.get(url)\n",
    "    temp = response.json()[\"current\"][\"temp\"]\n",
    "    \n",
    "    list_.append(temp)\n",
    "\n",
    "# update dataset\n",
    "dataset_weather = dataset_nominatim.copy()\n",
    "dataset_weather['temperature'] = list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy dataset\n",
    "dataset_weather2 = dataset_weather.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the dataset for future display\n",
    "dataset_weather2 = pd.concat([dataset_weather2]*8, ignore_index=True)\n",
    "dataset_weather2 = dataset_weather2.sort_values(\"id\", ascending=True)\n",
    "dataset_weather2 = dataset_weather2.reset_index(drop=True)\n",
    "dataset_weather2[\"day\"] = [\"day 1\", \"day 2\", \"day 3\", \"day 4\", \"day 5\", \"day 6\", \"day 7\", \"day 8\"]*35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieval of current temperatures and the next 7 days for each city\n",
    "list_city = []\n",
    "\n",
    "for i in range(len(dataset_weather2)):\n",
    "    url = \"https://api.openweathermap.org/data/2.5/onecall?lat=\" + dataset_weather2.latitude[i] + \"&lon=\" + dataset_weather2.longitude[i] + \"&exclude=minutely,hourly,alerts&appid=c75f7d44de1e2063f962807925d6dc7f&units=metric\"\n",
    "    response = requests.get(url)\n",
    "    daily = response.json()[\"daily\"]\n",
    "    list_day = []\n",
    "    \n",
    "    for j in range(len(daily)):\n",
    "        temp = daily[j][\"feels_like\"][\"day\"]\n",
    "        humidity = daily[j][\"humidity\"]\n",
    "        \n",
    "        dict_ = {\n",
    "            \"feels_temp\": temp,\n",
    "            \"humidity\": humidity\n",
    "        }\n",
    "        \n",
    "        list_day.append(dict_)\n",
    "    \n",
    "    list_city.append(list_day)\n",
    "\n",
    "# transformation of the previous result as a list for the temperature\n",
    "list_ = []\n",
    "\n",
    "for ville in range(len(dataset_weather)):\n",
    "    temp1 = list_city[ville]\n",
    "    \n",
    "    for day in range(8):\n",
    "        temp2 = temp1[day][\"feels_temp\"]\n",
    "        list_.append(temp2)\n",
    "\n",
    "dataset_weather2[\"day_temperature\"] = list_\n",
    "\n",
    "# transformation of the previous result as a list for humidity\n",
    "list_ = []\n",
    "\n",
    "for ville in range(len(dataset_weather)):\n",
    "    humidity1 = list_city[ville]\n",
    "    \n",
    "    for day in range(8):\n",
    "        humidity2 = humidity1[day][\"humidity\"]\n",
    "        list_.append(humidity2)\n",
    "\n",
    "dataset_weather2[\"humidity\"] = list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update dataset & export into CSV file\n",
    "dataset_weather2[\"latitude\"] = dataset_weather2[\"latitude\"].astype(float)\n",
    "dataset_weather2[\"longitude\"] = dataset_weather2[\"longitude\"].astype(float)\n",
    "dataset_weather2.to_csv(\"src/weather_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a5cbf13dbd0b57ea6fcb4b79c56f1a3c3ccfe47af6b515f49de13c71807f124"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
